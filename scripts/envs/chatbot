# all default common env var values are defined in scripts/envs/base file
# in order to override a default common env var value and/or add a custom
# env var used only for this sample you can list it here
export APP_NAME="chatbot"
export APP_DISPLAY_NAME="Chatbot Application"
export APP_DESC="Build your own Large language model (LLM)-enabled chat application. Pick from the model servers available or bring your own."
export APP_TAGS='["ai", "llamacpp", "vllm", "python"]'
export APP_RUN_COMMAND="streamlit run chatbot_ui.py"
export INIT_CONTAINER="quay.io/redhat-ai-dev/granite-7b-lab:latest"
export MODEL_SERVICE_CONTAINER="quay.io/ai-lab/llamacpp_python:latest"

export VLLM_CONTAINER="quay.io/rh-aiservices-bu/vllm-openai-ubi9:0.4.2"
export VLLM_MODEL_NAME="instructlab/granite-7b-lab"
export VLLM_MAX_MODEL_LEN=4096
export VLLM_MODEL_DESC="LAB (Large-scale Alignment for chatBots) is a novel synthetic data-based alignment tuning method for LLMs from IBM Research. Granite-7b-lab is a Granite-7b-base derivative model trained with the LAB methodology, using Mixtral-8x7b-Instruct as a teacher model."

# model configurations
export SUPPORT_LLM=true

# for gitlab case, since gitlab does not have pipeline webhook pre-set to trigger the initial build
export APP_INTERFACE_CONTAINER="quay.io/redhat-ai-dev/chatbot:latest"

